{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74eb8609-bd0c-4a26-94be-5cf56d9f58cb",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/OlivierGeorgeon/Developmental-AI-Lab/blob/master/docs/agent4.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# THE AGENT WHO SHIFTED WITH THE CONTEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef995-42ce-44ba-9f3b-8bfa808b08fe",
   "metadata": {},
   "source": [
    "# Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14a47d-ca87-4080-8f84-afcd2bc83170",
   "metadata": {},
   "source": [
    "Upon completing this lab, you will be able to implement a developmental agent driven by interactional motivation that adapts its next action based on the context of the previously enacted interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a16db8-1bd6-4e82-9cf6-2b37d996ffe8",
   "metadata": {},
   "source": [
    "## Define the Interaction class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44155c4a-d038-40b3-be33-e8cf77c5f976",
   "metadata": {},
   "source": [
    "Let's define an Interaction class that will be useful to intitialize the agent and to memorize the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96c3637-4161-49aa-9f1d-0d3342de92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"An interaction is a tuple (action, outcome) with a valence\"\"\"\n",
    "    def __init__(self, action, outcome, valence):\n",
    "        self.action = action\n",
    "        self.outcome = outcome\n",
    "        self.valence = valence\n",
    "\n",
    "    def key(self):\n",
    "        \"\"\" The key to find this interaction in the dictinary is the string '<action><outcome>'. \"\"\"\n",
    "        return f\"{self.action}{self.outcome}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\" Print interaction in the form '<action><outcome:<valence>' for debug.\"\"\"\n",
    "        return f\"{self.action}{self.outcome}:{self.valence}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Interactions are equal if they have the same key \"\"\"\n",
    "        return self.key() == other.key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152512a3-ef97-473a-91a7-9a36fe70ba33",
   "metadata": {},
   "source": [
    "## Define the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b81c3-5671-4ec6-bb7d-9db4f99c7c0b",
   "metadata": {},
   "source": [
    "The agent is initialized with the list of interactions \n",
    "\n",
    "The previous action and the predicted outcome are memorized in the attribute `_intended_interaction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0bf369-48ef-48d7-a92b-3c7ef8dc1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"Creating our agent\"\"\"\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\" Initialize the dictionary of interactions\"\"\"\n",
    "        self._interactions = {interaction.key(): interaction for interaction in _interactions}\n",
    "        self._intended_interaction = self._interactions[\"00\"]\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\" Tracing the previous cycle \"\"\"\n",
    "        previous_interaction = self._interactions[f\"{self._intended_interaction.action}{_outcome}\"]\n",
    "        print(f\"Action: {self._intended_interaction.action}, Prediction: {self._intended_interaction.outcome}, Outcome: {_outcome}, \" \n",
    "              f\"Prediction: {self._intended_interaction.outcome == _outcome}, Valence: {previous_interaction.valence})\")\n",
    "\n",
    "        \"\"\" Computing the next interaction to try to enact \"\"\"\n",
    "        # TODO: Implement the agent's decision mechanism\n",
    "        intended_action = 0\n",
    "        # TODO: Implement the agent's prediction mechanism\n",
    "        intended_outcome = 0\n",
    "        # Memorize the intended interaction\n",
    "        self._intended_interaction = self._interactions[f\"{intended_action}{intended_outcome}\"]\n",
    "        return intended_action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1c38f-c8ed-48e5-bc6a-e7078ed3e5e4",
   "metadata": {},
   "source": [
    "## Environment1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d65ca61-9386-4260-a406-ec766063569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment1:\n",
    "    \"\"\" In Environment 1, action 0 yields outcome 0, action 1 yields outcome 1 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        # return int(input(\"entre 0 1 ou 2\"))\n",
    "        if _action == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6d7d6-5444-4778-b97a-cc5bd34c6cd2",
   "metadata": {},
   "source": [
    "## Environment2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ae8fba-72aa-4194-be5a-2f27a1637e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment2:\n",
    "    \"\"\" In Environment 2, action 0 yields outcome 1, action 1 yields outcome 0 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        if _action == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab7280-a559-4fc2-8668-4285aac82d8d",
   "metadata": {},
   "source": [
    "## Environment3 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df2375-680e-4df9-a0ed-e84802aac1a4",
   "metadata": {},
   "source": [
    "Environment 3 yields outcome 1 only when the agent alternates actions 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bf9a4ba-2703-49e9-a63f-b72c08b8663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment3:\n",
    "    \"\"\" Environment 3 yields outcome 1 only when the agent alternates actions 0 and 1 \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializing Environment3 \"\"\"\n",
    "        self.previous_action = 0\n",
    "\n",
    "    def outcome(self, _action):\n",
    "        if _action == self.previous_action:\n",
    "            _outcome = 0\n",
    "        else:\n",
    "            _outcome = 1\n",
    "        self.previous_action = _action\n",
    "        return _outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f49f7-9352-4938-9ee2-7d8a7bb5065a",
   "metadata": {},
   "source": [
    "## Initialize the interactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59da5f51-d5db-4cf4-8bd0-036ec11eaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = [\n",
    "    Interaction(0,0,-1),\n",
    "    Interaction(0,1,1),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1),\n",
    "    Interaction(2,0,-1),\n",
    "    Interaction(2,1,1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d25cea-a183-45c5-a624-1345aace245a",
   "metadata": {},
   "source": [
    "Interactions are initialized with their action, their outcome, and their valence:\n",
    "\n",
    "|| outcome 0 | outcome 1|\n",
    "|---|---|---|\n",
    "| action 0| -1 | 1 |\n",
    "| action 1 | -1 | 1 |\n",
    "| action 2 | -1 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095ec84-3fcd-455c-bb3b-f9a72980048e",
   "metadata": {},
   "source": [
    "## Instantiate the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33066d34-7f06-4b38-97b8-d7d5adbb237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16279c4-936b-4f37-a0c9-ca4b77609adf",
   "metadata": {},
   "source": [
    "## Instantiate the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b3c8c8-0cbd-4f64-a97c-61519ad24dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Environment3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ce510-9438-47d1-ac88-ab79c063d592",
   "metadata": {},
   "source": [
    "## Test run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6d76df-89e4-4ab3-a327-afa813a27325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1)\n"
     ]
    }
   ],
   "source": [
    "outcome = 0\n",
    "for i in range(10):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febad285-e8e5-4c24-a46e-e9519a27581c",
   "metadata": {},
   "source": [
    "Observe that in Envirnment3, the agent obtains only negative valences. To obtain a positive valence, it must select a different action on each interaction cycle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019f138-a218-44b2-964a-8095fbe891a7",
   "metadata": {},
   "source": [
    "# PRELIMINARY EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9daa278-434e-43ce-8520-8fabef69cd83",
   "metadata": {},
   "source": [
    "Execute the agent in Environment1. Observe that it obtains a negative valence. \n",
    "\n",
    "Execute the agent in Environment2. Observe that it obtains a positive valence. \n",
    "\n",
    "Now you see the goal of this assignement: design an agent that can obtain positive valences when it is run either in Environment1 or in Environment2 or in Environment3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50d96e-4f12-4531-a122-9d13d8bd8639",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199faee9-a546-4d86-8e09-484bf2212523",
   "metadata": {},
   "source": [
    "Implement Agent4 that obtains positive valences in either Environment 1, 2, or 3. \n",
    "\n",
    "Agent4 must be able to predict the outcome resulting from its next action depending on the context of the previous interaction. \n",
    "Based on this prediction, it must select the action that will yield the heighest valence. \n",
    "\n",
    "To do so, at the end of cycle `t`, Agent4 must memorize `interaction_t = (action_t, outcome_t)` that was just enacted. \n",
    "The agent must choose the next `interaction_t+1` based on `interaction_t` (the context).\n",
    "For each possible `action_t+1`, the agent must predict the expected `outcome_t+1`. \n",
    "Based on this prediction, it must select the action that yields the highest `valence_t+1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b9a28-121c-4379-8701-1d49ad197b8d",
   "metadata": {},
   "source": [
    "## Create Agent4 by overriding the class Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9ba2b-8129-4bf7-82dc-074803f95bdf",
   "metadata": {},
   "source": [
    "You may add any attribute and method you deem usefull to the class Agent4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85b966d4-aca5-4a08-8413-d4906fdbbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent4(Agent):\n",
    "    def __init__(self, _interactions):\n",
    "        \"\"\"Creating our context-aware agent\"\"\"\n",
    "        super().__init__(_interactions)\n",
    "        # Context memory: stores sequences (previous_interaction, action) -> outcome\n",
    "        self.context_memory = {}\n",
    "        self.previous_interaction = None\n",
    "        # Boredom management\n",
    "        self.correct_predictions = 0\n",
    "        self.boredom_threshold = 3\n",
    "        \n",
    "    def action(self, _outcome):\n",
    "        \"\"\"Tracing the previous cycle\"\"\"\n",
    "        # Get the enacted interaction\n",
    "        enacted_interaction = self._interactions[f\"{self._intended_interaction.action}{_outcome}\"]\n",
    "        \n",
    "        # Check if prediction was correct\n",
    "        prediction_correct = (self._intended_interaction.outcome == _outcome)\n",
    "        \n",
    "        if prediction_correct:\n",
    "            self.correct_predictions += 1\n",
    "        else:\n",
    "            self.correct_predictions = 0\n",
    "        \n",
    "        print(f\"Action: {self._intended_interaction.action}, \"\n",
    "              f\"Prediction: {self._intended_interaction.outcome}, \"\n",
    "              f\"Outcome: {_outcome}, \"\n",
    "              f\"Prediction_correct: {prediction_correct}, \"\n",
    "              f\"Valence: {enacted_interaction.valence})\")\n",
    "        \n",
    "        # Update context memory if we have a previous interaction\n",
    "        if self.previous_interaction is not None:\n",
    "            context_key = (self.previous_interaction.key(), self._intended_interaction.action)\n",
    "            self.context_memory[context_key] = _outcome\n",
    "\n",
    "        \"\"\"Computing the next interaction to try to enact\"\"\"\n",
    "        # TODO: Implement the agent's decision mechanism\n",
    "        # ✅ IMPLÉMENTATION DU MÉCANISME DE DÉCISION CONTEXTUEL\n",
    "        \n",
    "        # If bored, add some randomness\n",
    "        if self.correct_predictions >= self.boredom_threshold:\n",
    "            import random\n",
    "            if random.random() < 0.3:\n",
    "                random_action = random.choice([0, 1, 2])\n",
    "                context_key = (enacted_interaction.key(), random_action)\n",
    "                if context_key in self.context_memory:\n",
    "                    predicted_outcome = self.context_memory[context_key]\n",
    "                else:\n",
    "                    predicted_outcome = 0\n",
    "                self._intended_interaction = self._interactions[f\"{random_action}{predicted_outcome}\"]\n",
    "                self.previous_interaction = enacted_interaction\n",
    "                self.correct_predictions = 0\n",
    "                return random_action\n",
    "        \n",
    "        # Choose the best action based on context and valence\n",
    "        best_interaction = None\n",
    "        best_valence = -float('inf')\n",
    "        \n",
    "        for action in [0, 1, 2]:\n",
    "            # TODO: Implement the agent's prediction mechanism\n",
    "            # ✅ IMPLÉMENTATION DU MÉCANISME D'ANTICIPATION CONTEXTUEL\n",
    "            \n",
    "            # Predict outcome based on context\n",
    "            context_key = (enacted_interaction.key(), action)\n",
    "            \n",
    "            if context_key in self.context_memory:\n",
    "                predicted_outcome = self.context_memory[context_key]\n",
    "            else:\n",
    "                predicted_outcome = 0\n",
    "            \n",
    "            # Get the interaction for this action-outcome pair\n",
    "            interaction_key = f\"{action}{predicted_outcome}\"\n",
    "            candidate_interaction = self._interactions[interaction_key]\n",
    "            \n",
    "            # Evaluate this candidate\n",
    "            if candidate_interaction.valence > best_valence:\n",
    "                best_valence = candidate_interaction.valence\n",
    "                best_interaction = candidate_interaction\n",
    "            elif candidate_interaction.valence == best_valence and best_interaction is not None:\n",
    "                import random\n",
    "                if random.random() < 0.5:\n",
    "                    best_interaction = candidate_interaction\n",
    "        \n",
    "        # Fallback if no good interaction found\n",
    "        if best_interaction is None:\n",
    "            best_interaction = self._interactions[\"00\"]\n",
    "        \n",
    "        # Memorize for next cycle\n",
    "        self.previous_interaction = enacted_interaction\n",
    "        self._intended_interaction = best_interaction\n",
    "        \n",
    "        return best_interaction.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b3f5c-f48c-45ad-bf1d-4a703bac64af",
   "metadata": {},
   "source": [
    "## Test your Agent4 in Environment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8025780-7d39-442d-9600-b40641e6d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 1, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 2, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n"
     ]
    }
   ],
   "source": [
    "a = Agent4(interactions)\n",
    "e = Environment1()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02f401-3a78-4ced-9b8c-3b602c7be482",
   "metadata": {},
   "source": [
    "## Test your Agent4 in Environment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925fb5f1-1eb6-4dee-a59b-fd6384e123d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n"
     ]
    }
   ],
   "source": [
    "a = Agent4(interactions)\n",
    "e = Environment2()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ebe13-605e-4068-ab57-06416f898790",
   "metadata": {},
   "source": [
    "## Test your Agent4 in Environment3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "835595f7-512e-46aa-b140-3e2b6c43eea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 1, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 2, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 2, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: -1)\n",
      "Action: 1, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 2, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n"
     ]
    }
   ],
   "source": [
    "a = Agent4(interactions)\n",
    "e = Environment3()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc8226-b4ac-49c7-b1a8-9b17adc19964",
   "metadata": {},
   "source": [
    "## Test your Agent4 with interactions that have other valences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01175431-ead3-480e-b8e3-e20ee9321379",
   "metadata": {},
   "source": [
    "Replace the valences of interactions with your choice in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49fdfd38-0d4e-48a3-ab0f-87177c2da97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 0)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 0)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 0)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 0)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n"
     ]
    }
   ],
   "source": [
    "# Choose different valence of interactions\n",
    "interactions = [\n",
    "    Interaction(0,0,1),\n",
    "    Interaction(0,1,0),\n",
    "    Interaction(1,0,-1),\n",
    "    Interaction(1,1,1),\n",
    "    Interaction(2,0,-1),\n",
    "    Interaction(2,1,1)\n",
    "]\n",
    "# Run the agent\n",
    "a = Agent4(interactions)\n",
    "e = Environment3()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1c321-c33f-497e-8219-a0904ab6ebab",
   "metadata": {},
   "source": [
    "## Test your agent in the Turtle environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71630824-e023-49b7-a143-6ffccae07209",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ColabTurtle in /home/amine/Bureau/M2/Fondamentaux_IA/Artificial_Intelligence_and_Cognition/IAD/Developmental-AI-Lab/env/lib/python3.13/site-packages (2.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# @title Install the turtle environment\n",
    "!pip3 install ColabTurtle\n",
    "from ColabTurtle.Turtle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f35913a4-4426-4e50-ba74-6790e579fb80",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# @title Initialize the turtle environment\n",
    "\n",
    "BORDER_WIDTH = 20\n",
    "\n",
    "class ColabTurtleEnvironment:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Creating the Turtle window \"\"\"\n",
    "        bgcolor(\"lightGray\")\n",
    "        penup()\n",
    "        goto(window_width() / 2, window_height()/2)\n",
    "        face(0)\n",
    "        pendown()\n",
    "        color(\"green\")\n",
    "\n",
    "    def outcome(self, action):\n",
    "        \"\"\" Enacting an action and returning the outcome \"\"\"\n",
    "        _outcome = 0\n",
    "        for i in range(10):\n",
    "            # _outcome = 0\n",
    "            if action == 0:\n",
    "                # move forward\n",
    "                forward(10)\n",
    "            elif action == 1:\n",
    "                # rotate left\n",
    "                left(4)\n",
    "                forward(2)\n",
    "            elif action == 2:\n",
    "                # rotate right\n",
    "                right(4)\n",
    "                forward(2)\n",
    "\n",
    "            # Bump on screen edge and return outcome 1\n",
    "            if xcor() < BORDER_WIDTH:\n",
    "                goto(BORDER_WIDTH, ycor())\n",
    "                _outcome = 1\n",
    "            if xcor() > window_width() - BORDER_WIDTH:\n",
    "                goto(window_width() - BORDER_WIDTH, ycor())\n",
    "                _outcome = 1\n",
    "            if ycor() < BORDER_WIDTH:\n",
    "                goto(xcor(), BORDER_WIDTH)\n",
    "                _outcome = 1\n",
    "            if ycor() > window_height() - BORDER_WIDTH:\n",
    "                goto(xcor(), window_height() -BORDER_WIDTH)\n",
    "                _outcome = 1\n",
    "\n",
    "            # Change color\n",
    "            if _outcome == 0:\n",
    "                color(\"green\")\n",
    "            else:\n",
    "                # Finit l'interaction\n",
    "                color(\"red\")\n",
    "                # if action == 0:\n",
    "                #     break\n",
    "                if action == 1:\n",
    "                    for j in range(10):\n",
    "                        left(4)\n",
    "                elif action == 2:\n",
    "                    for j in range(10):\n",
    "                        right(4)\n",
    "                break\n",
    "\n",
    "        return _outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fb4b183-a761-47c8-a3a5-957467dd5675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <svg width=\"800\" height=\"500\">\n",
       "        <rect width=\"100%\" height=\"100%\" fill=\"lightgray\"/>\n",
       "        <line x1=\"400.0\" y1=\"250.0\" x2=\"410.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"410.0\" y1=\"250.0\" x2=\"420.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"420.0\" y1=\"250.0\" x2=\"430.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"430.0\" y1=\"250.0\" x2=\"440.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"440.0\" y1=\"250.0\" x2=\"450.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"450.0\" y1=\"250.0\" x2=\"460.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"460.0\" y1=\"250.0\" x2=\"470.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"470.0\" y1=\"250.0\" x2=\"480.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"480.0\" y1=\"250.0\" x2=\"490.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"490.0\" y1=\"250.0\" x2=\"500.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"500.0\" y1=\"250.0\" x2=\"510.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"510.0\" y1=\"250.0\" x2=\"520.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"520.0\" y1=\"250.0\" x2=\"530.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"530.0\" y1=\"250.0\" x2=\"540.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"540.0\" y1=\"250.0\" x2=\"550.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"550.0\" y1=\"250.0\" x2=\"560.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"560.0\" y1=\"250.0\" x2=\"570.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"570.0\" y1=\"250.0\" x2=\"580.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"580.0\" y1=\"250.0\" x2=\"590.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"590.0\" y1=\"250.0\" x2=\"600.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"600.0\" y1=\"250.0\" x2=\"610.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"610.0\" y1=\"250.0\" x2=\"620.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"620.0\" y1=\"250.0\" x2=\"630.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"630.0\" y1=\"250.0\" x2=\"640.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"640.0\" y1=\"250.0\" x2=\"650.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"650.0\" y1=\"250.0\" x2=\"660.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"660.0\" y1=\"250.0\" x2=\"670.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"670.0\" y1=\"250.0\" x2=\"680.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"680.0\" y1=\"250.0\" x2=\"690.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"690.0\" y1=\"250.0\" x2=\"700.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"700.0\" y1=\"250.0\" x2=\"710.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"710.0\" y1=\"250.0\" x2=\"720.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"720.0\" y1=\"250.0\" x2=\"730.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"730.0\" y1=\"250.0\" x2=\"740.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"740.0\" y1=\"250.0\" x2=\"750.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"750.0\" y1=\"250.0\" x2=\"760.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"760.0\" y1=\"250.0\" x2=\"770.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"770.0\" y1=\"250.0\" x2=\"780.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"780.0\" y1=\"250.0\" x2=\"790.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"790.0\" y1=\"250.0\" x2=\"780\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:green;stroke-width:4\"/><line x1=\"780\" y1=\"250.0\" x2=\"790.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"790.0\" y1=\"250.0\" x2=\"780\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"780\" y1=\"250.0\" x2=\"790.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"790.0\" y1=\"250.0\" x2=\"780\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"780\" y1=\"250.0\" x2=\"790.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"790.0\" y1=\"250.0\" x2=\"780\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"780\" y1=\"250.0\" x2=\"790.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"790.0\" y1=\"250.0\" x2=\"780\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"780\" y1=\"250.0\" x2=\"790.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"790.0\" y1=\"250.0\" x2=\"780\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"780\" y1=\"250.0\" x2=\"790.0\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/><line x1=\"790.0\" y1=\"250.0\" x2=\"780\" y2=\"250.0\" stroke-linecap=\"round\" style=\"stroke:red;stroke-width:4\"/>\n",
       "        <g visibility=visible transform=\"rotate(90,780,250.0) translate(762, 232.0)\">\n",
       "<path style=\" stroke:none;fill-rule:evenodd;fill:red;fill-opacity:1;\" d=\"M 18.214844 0.632812 C 16.109375 1.800781 15.011719 4.074219 15.074219 7.132812 L 15.085938 7.652344 L 14.785156 7.496094 C 13.476562 6.824219 11.957031 6.671875 10.40625 7.066406 C 8.46875 7.550781 6.515625 9.15625 4.394531 11.992188 C 3.0625 13.777344 2.679688 14.636719 3.042969 15.027344 L 3.15625 15.152344 L 3.519531 15.152344 C 4.238281 15.152344 4.828125 14.886719 8.1875 13.039062 C 9.386719 12.378906 10.371094 11.839844 10.378906 11.839844 C 10.386719 11.839844 10.355469 11.929688 10.304688 12.035156 C 9.832031 13.09375 9.257812 14.820312 8.96875 16.078125 C 7.914062 20.652344 8.617188 24.53125 11.070312 27.660156 C 11.351562 28.015625 11.363281 27.914062 10.972656 28.382812 C 8.925781 30.84375 7.945312 33.28125 8.238281 35.1875 C 8.289062 35.527344 8.28125 35.523438 8.917969 35.523438 C 10.941406 35.523438 13.074219 34.207031 15.136719 31.6875 C 15.359375 31.417969 15.328125 31.425781 15.5625 31.574219 C 16.292969 32.042969 18.023438 32.964844 18.175781 32.964844 C 18.335938 32.964844 19.941406 32.210938 20.828125 31.71875 C 20.996094 31.625 21.136719 31.554688 21.136719 31.558594 C 21.203125 31.664062 21.898438 32.414062 22.222656 32.730469 C 23.835938 34.300781 25.5625 35.132812 27.582031 35.300781 C 27.90625 35.328125 27.9375 35.308594 28.007812 34.984375 C 28.382812 33.242188 27.625 30.925781 25.863281 28.425781 L 25.542969 27.96875 L 25.699219 27.785156 C 28.945312 23.960938 29.132812 18.699219 26.257812 11.96875 L 26.207031 11.84375 L 27.945312 12.703125 C 31.53125 14.476562 32.316406 14.800781 33.03125 14.800781 C 33.976562 14.800781 33.78125 13.9375 32.472656 12.292969 C 28.519531 7.355469 25.394531 5.925781 21.921875 7.472656 L 21.558594 7.636719 L 21.578125 7.542969 C 21.699219 6.992188 21.761719 5.742188 21.699219 5.164062 C 21.496094 3.296875 20.664062 1.964844 19.003906 0.855469 C 18.480469 0.503906 18.457031 0.5 18.214844 0.632812\"/>\n",
       "</g>\n",
       "      </svg>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction_correct: True, Valence: 1)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 0)\n",
      "Action: 0, Prediction: 0, Outcome: 1, Prediction_correct: False, Valence: 0)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 0)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 0)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 0)\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction_correct: True, Valence: 0)\n"
     ]
    }
   ],
   "source": [
    "# @title Run the turtle environment\n",
    "initializeTurtle()\n",
    "\n",
    "# Parameterize the rendering\n",
    "bgcolor(\"lightGray\")\n",
    "penup()\n",
    "goto(window_width() / 2, window_height()/2)\n",
    "face(0)\n",
    "pendown()\n",
    "color(\"green\")\n",
    "speed(10)\n",
    "\n",
    "a = Agent4(interactions)\n",
    "e = ColabTurtleEnvironment()\n",
    "\n",
    "outcome = 0\n",
    "for i in range(10):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15a134-34a6-4039-9b43-f8fd76d93b5e",
   "metadata": {},
   "source": [
    "## Report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e661c15-c1ed-4512-a1d9-0fbdb8f91879",
   "metadata": {},
   "source": [
    "Explain what you programmed and what results you observed. Export this document as PDF including your code, the traces you obtained, and your explanations below (no more than a few paragraphs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc0899-eee2-404a-baf6-47741067e7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
