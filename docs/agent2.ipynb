{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74eb8609-bd0c-4a26-94be-5cf56d9f58cb",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/OlivierGeorgeon/Developmental-AI-Lab/blob/master/docs/agent2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# THE AGENT WHO THRIVED ON GOOD VIBES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11bd8cd-4c59-427b-b0cb-84d3de0c14bc",
   "metadata": {},
   "source": [
    "# Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52effea-74dd-43c7-989a-7075634d3ccc",
   "metadata": {},
   "source": [
    "Upon completing this lab, you will be able to implement agents driven by a type of intrinsic motivation called 'interactional motivation.' This refers to the drive to engage in sensorimotor interactions that have a positive valence while avoiding those that have a negative valence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152512a3-ef97-473a-91a7-9a36fe70ba33",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Define the Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f0bf369-48ef-48d7-a92b-3c7ef8dc1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, _valences):\n",
    "        \"\"\" Creating our agent \"\"\"\n",
    "        self._valences = _valences\n",
    "        self._action = None\n",
    "        self._predicted_outcome = None\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\" tracing the previous cycle \"\"\"\n",
    "        if self._action is not None:\n",
    "            print(f\"Action: {self._action}, Prediction: {self._predicted_outcome}, Outcome: {_outcome}, \" \n",
    "                  f\"Prediction: {self._predicted_outcome == _outcome}, Valence: {self._valences[self._action][_outcome]}\")\n",
    "\n",
    "        \"\"\" Computing the next action to enact \"\"\"\n",
    "        # TODO: Implement the agent's decision mechanism\n",
    "        self._action = 0\n",
    "        # TODO: Implement the agent's anticipation mechanism\n",
    "        self._predicted_outcome = 0\n",
    "        return self._action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1c38f-c8ed-48e5-bc6a-e7078ed3e5e4",
   "metadata": {},
   "source": [
    "## Environment1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d65ca61-9386-4260-a406-ec766063569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment1:\n",
    "    \"\"\" In Environment 1, action 0 yields outcome 0, action 1 yields outcome 1 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        # return int(input(\"entre 0 1 ou 2\"))\n",
    "        if _action == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6d7d6-5444-4778-b97a-cc5bd34c6cd2",
   "metadata": {},
   "source": [
    "## Environment2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91ae8fba-72aa-4194-be5a-2f27a1637e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment2:\n",
    "    \"\"\" In Environment 2, action 0 yields outcome 1, action 1 yields outcome 0 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        if _action == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a16db8-1bd6-4e82-9cf6-2b37d996ffe8",
   "metadata": {},
   "source": [
    "## Define the valence of interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59da5f51-d5db-4cf4-8bd0-036ec11eaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valences = [[-1, 1], \n",
    "            [1, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d25cea-a183-45c5-a624-1345aace245a",
   "metadata": {},
   "source": [
    "The valence table specifies the valence of each interaction. An interaction is a tuple (action, outcome):\n",
    "\n",
    "|| outcome 0 | outcome 1 |\n",
    "|---|---|---|\n",
    "| action 0 | -1 | 1 |\n",
    "| action 1 | 1 | -1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095ec84-3fcd-455c-bb3b-f9a72980048e",
   "metadata": {},
   "source": [
    "## Instantiate the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "180453e4-128a-4f68-bb5f-2d4daf888d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent(valences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16279c4-936b-4f37-a0c9-ca4b77609adf",
   "metadata": {},
   "source": [
    "## Instantiate the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17b3c8c8-0cbd-4f64-a97c-61519ad24dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Environment1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ce510-9438-47d1-ac88-ab79c063d592",
   "metadata": {},
   "source": [
    "## Test run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f6d76df-89e4-4ab3-a327-afa813a27325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1\n"
     ]
    }
   ],
   "source": [
    "outcome = 0\n",
    "for i in range(10):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febad285-e8e5-4c24-a46e-e9519a27581c",
   "metadata": {},
   "source": [
    "Observe that, on each interaction cycle, the agent is mildly satisfied. On one hand, the agent made correct predictions, on the other hand, it experienced negative valence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019f138-a218-44b2-964a-8095fbe891a7",
   "metadata": {},
   "source": [
    "# PRELIMINARY EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9daa278-434e-43ce-8520-8fabef69cd83",
   "metadata": {},
   "source": [
    "Execute the agent in Environment2. Observed that it obtains a positive valence. \n",
    "\n",
    "Modify the valence table to give a positive valence when the agent selects action `0` and obtains outcome `0`.\n",
    "Observe that this agent obtains a positive valence in Environment1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50d96e-4f12-4531-a122-9d13d8bd8639",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199faee9-a546-4d86-8e09-484bf2212523",
   "metadata": {},
   "source": [
    "Implement Agent2 that selects actions that, it predicts, will result in an interaction that have a positive valence. \n",
    "\n",
    "Only when the agent gets bored does it select an action which it predicts to result in an interaction that have a negative valence. \n",
    "\n",
    "In the trace, you should see that the agent learns to obtain a positive valence during several interaction cycles.\n",
    "When the agent gest bored, it occasionnaly selects an action that may result in a negative valence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b9a28-121c-4379-8701-1d49ad197b8d",
   "metadata": {},
   "source": [
    "## Create Agent2 by overriding the class Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85b966d4-aca5-4a08-8413-d4906fdbbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent2(Agent):\n",
    "    def __init__(self, _valences):\n",
    "        \"\"\"Creating our hedonist agent\"\"\"\n",
    "        super().__init__(_valences)\n",
    "        # Memory: stores the last observed outcome for each action\n",
    "        self.memory = {}\n",
    "        # Counter for consecutive correct predictions\n",
    "        self.correct_count = 0\n",
    "        # Boredom threshold\n",
    "        self.boredom_threshold = 4\n",
    "        \n",
    "    def action(self, _outcome):\n",
    "        \"\"\"Tracing the previous cycle\"\"\"\n",
    "        if self._action is not None:\n",
    "            # Update memory with the observed outcome\n",
    "            self.memory[self._action] = _outcome\n",
    "            \n",
    "            # Check if prediction was correct\n",
    "            satisfied = (self._predicted_outcome == _outcome)\n",
    "            \n",
    "            # Update correct prediction counter\n",
    "            if satisfied:\n",
    "                self.correct_count += 1\n",
    "            else:\n",
    "                self.correct_count = 0\n",
    "            \n",
    "            # Calculate valence\n",
    "            valence = self._valences[self._action][_outcome]\n",
    "            \n",
    "            # Check for boredom\n",
    "            bored = (self.correct_count >= self.boredom_threshold)\n",
    "            \n",
    "            print(f\"Action: {self._action}, Prediction: {self._predicted_outcome}, \"\n",
    "                  f\"Outcome: {_outcome}, Prediction: {satisfied}, Valence: {valence}, Bored: {bored}\")\n",
    "        \n",
    "        \"\"\"Computing the next action to enact\"\"\"\n",
    "        # TODO: Implement the agent's decision mechanism\n",
    "        # ✅ IMPLÉMENTATION DU MÉCANISME DE DÉCISION BASÉ SUR LA VALENCE\n",
    "        if self.correct_count >= self.boredom_threshold:\n",
    "            # Bored: try a different action\n",
    "            self._action = 1 - self._action\n",
    "            self.correct_count = 0\n",
    "        else:\n",
    "            # Not bored: choose the action with the best anticipated valence\n",
    "            best_action = None\n",
    "            best_valence = -float('inf')\n",
    "            \n",
    "            for action in [0, 1]:\n",
    "                if action in self.memory:\n",
    "                    predicted_outcome = self.memory[action]\n",
    "                    predicted_valence = self._valences[action][predicted_outcome]\n",
    "                    \n",
    "                    if predicted_valence > best_valence:\n",
    "                        best_valence = predicted_valence\n",
    "                        best_action = action\n",
    "            \n",
    "            if best_action is not None:\n",
    "                self._action = best_action\n",
    "            elif self._action is None:\n",
    "                self._action = 0\n",
    "        \n",
    "        # TODO: Implement the agent's anticipation mechanism\n",
    "        # ✅ IMPLÉMENTATION DU MÉCANISME D'ANTICIPATION\n",
    "        if self._action in self.memory:\n",
    "            self._predicted_outcome = self.memory[self._action]\n",
    "        else:\n",
    "            self._predicted_outcome = 0\n",
    "        \n",
    "        return self._action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b3f5c-f48c-45ad-bf1d-4a703bac64af",
   "metadata": {},
   "source": [
    "## Test your Agent2 in Environment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8025780-7d39-442d-9600-b40641e6d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 1, Prediction: False, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: True\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: True\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: True\n",
      "Action: 1, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n"
     ]
    }
   ],
   "source": [
    "a = Agent2(valences)\n",
    "e = Environment1()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02f401-3a78-4ced-9b8c-3b602c7be482",
   "metadata": {},
   "source": [
    "## Test your Agent2 in Environment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "925fb5f1-1eb6-4dee-a59b-fd6384e123d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 1, Prediction: False, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction: True, Valence: 1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: 1, Bored: False\n"
     ]
    }
   ],
   "source": [
    "a = Agent2(valences)\n",
    "e = Environment2()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc8226-b4ac-49c7-b1a8-9b17adc19964",
   "metadata": {},
   "source": [
    "# Test your agent with a different valence table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a300f0-5c05-4bbf-a9a4-7ed17af0aae7",
   "metadata": {},
   "source": [
    "Note that, depending on the valence that you define, it may be impossible for the agent to obtain a positive valence in some environments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49fdfd38-0d4e-48a3-ab0f-87177c2da97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 1, Prediction: False, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 0, Prediction: True, Valence: -1, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Prediction: True, Valence: -1, Bored: False\n"
     ]
    }
   ],
   "source": [
    "# Choose different valences\n",
    "valences = [[1, -1], \n",
    "            [-1, 1]]\n",
    "# Run the agent\n",
    "a = Agent2(valences)\n",
    "e = Environment2()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15a134-34a6-4039-9b43-f8fd76d93b5e",
   "metadata": {},
   "source": [
    "## Report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e661c15-c1ed-4512-a1d9-0fbdb8f91879",
   "metadata": {},
   "source": [
    "Explain what you programmed and what results you observed. Export this document as PDF including your code, the traces you obtained, and your explanations below (no more than a few paragraphs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc0899-eee2-404a-baf6-47741067e7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
