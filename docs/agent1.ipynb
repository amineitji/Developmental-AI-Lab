{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74eb8609-bd0c-4a26-94be-5cf56d9f58cb",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/OlivierGeorgeon/Developmental-AI-Lab/blob/master/docs/agent1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec58b3-e210-4a78-9610-f6615254de29",
   "metadata": {},
   "source": [
    "# THE AGENT WHO AVOIDED THE ORDINARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ddba6-0466-42c0-9ced-629b34a41c65",
   "metadata": {},
   "source": [
    "In this lab, you will implement the simplest agent that learns to predict the outcome of its actions and tries another action when it gets bored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e901c30-aeeb-402b-9095-d9f2a6238368",
   "metadata": {},
   "source": [
    "## Learning objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dde4b4-1767-4cab-aae9-0c97d2436e68",
   "metadata": {},
   "source": [
    "Upon completing this lab, you will be able to implement artificial agents based on the 'conceptual inversion of the interaction cycle.'\n",
    "In this framwork, the agent starts by taking action and then receives a sensory signal which is an outcome of action. This contrasts with traditional AI agents, which first perceive their environment before deciding how to act."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152512a3-ef97-473a-91a7-9a36fe70ba33",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Define the Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0bf369-48ef-48d7-a92b-3c7ef8dc1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        \"\"\" Creating our agent \"\"\"\n",
    "        self._action = None\n",
    "        self._predicted_outcome = None\n",
    "\n",
    "    def action(self, _outcome):\n",
    "        \"\"\" tracing the previous cycle \"\"\"\n",
    "        if self._action is not None:\n",
    "            print(f\"Action: {self._action}, Prediction: {self._predicted_outcome}, Outcome: {_outcome}, \" \n",
    "                  f\"Satisfaction: {self._predicted_outcome == _outcome}\")\n",
    "\n",
    "        \"\"\" Computing the next action to enact \"\"\"\n",
    "        # TODO: Implement the agent's decision mechanism\n",
    "        self._action = 0\n",
    "        # TODO: Implement the agent's anticipation mechanism\n",
    "        self._predicted_outcome = 0\n",
    "        return self._action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1c38f-c8ed-48e5-bc6a-e7078ed3e5e4",
   "metadata": {},
   "source": [
    "## Environment1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d65ca61-9386-4260-a406-ec766063569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment1:\n",
    "    \"\"\" In Environment 1, action 0 yields outcome 0, action 1 yields outcome 1 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        # return int(input(\"entre 0 1 ou 2\"))\n",
    "        if _action == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6d7d6-5444-4778-b97a-cc5bd34c6cd2",
   "metadata": {},
   "source": [
    "## Environment2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ae8fba-72aa-4194-be5a-2f27a1637e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment2:\n",
    "    \"\"\" In Environment 2, action 0 yields outcome 1, action 1 yields outcome 0 \"\"\"\n",
    "    def outcome(self, _action):\n",
    "        if _action == 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095ec84-3fcd-455c-bb3b-f9a72980048e",
   "metadata": {},
   "source": [
    "## Instantiate the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180453e4-128a-4f68-bb5f-2d4daf888d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16279c4-936b-4f37-a0c9-ca4b77609adf",
   "metadata": {},
   "source": [
    "## Instantiate the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b3c8c8-0cbd-4f64-a97c-61519ad24dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Environment1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ce510-9438-47d1-ac88-ab79c063d592",
   "metadata": {},
   "source": [
    "## Test run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6d76df-89e4-4ab3-a327-afa813a27325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True\n"
     ]
    }
   ],
   "source": [
    "outcome = 0\n",
    "for i in range(10):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febad285-e8e5-4c24-a46e-e9519a27581c",
   "metadata": {},
   "source": [
    "Observe that, on each interaction cycle, the agent correctly predicts the outcomes. The agent's satisfaction is True because its predictions are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019f138-a218-44b2-964a-8095fbe891a7",
   "metadata": {},
   "source": [
    "# PRELIMINARY EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9daa278-434e-43ce-8520-8fabef69cd83",
   "metadata": {},
   "source": [
    "Run the agent in Environment2. Observe that its satisfaction becomes False. This agent is not satisfied in Environment2!\n",
    "\n",
    "Now you see the goal of this assignment: design an agent that learns to be satisfied when it is run either in Environment1 or in Environment2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50d96e-4f12-4531-a122-9d13d8bd8639",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199faee9-a546-4d86-8e09-484bf2212523",
   "metadata": {},
   "source": [
    "Implement Agent1 that: \n",
    "* learns to predict the outcome of its actions \n",
    "* chooses a different action when its predictions have been correct for 4 times in a row\n",
    "\n",
    "The agent can choose two possible actions `0` or `1`, and can recieve two possible outcomes: `0` or `1`.\n",
    "\n",
    "It computes the prediction on the assumption that the same action always yeilds the same outcome in a given environment. \n",
    "You must thus implement a memory of the obtained outcomes for each action. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b9a28-121c-4379-8701-1d49ad197b8d",
   "metadata": {},
   "source": [
    "## Create your own agent by overriding the class Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de44c541-3245-45c3-879b-7865bf02ff94",
   "metadata": {},
   "source": [
    "Create an agent that learns to correctly predict the outcome of its actions in both Environment1 and Environment2.\n",
    "\n",
    "You may add any class attribute or method you deem useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85b966d4-aca5-4a08-8413-d4906fdbbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent1(Agent):\n",
    "    def __init__(self):\n",
    "        \"\"\"Creating our learning agent that avoids boredom\"\"\"\n",
    "        super().__init__()\n",
    "        # Memory: stores the last observed outcome for each action\n",
    "        self.memory = {}  # {action: outcome}\n",
    "        # Counter for consecutive correct predictions\n",
    "        self.correct_count = 0\n",
    "        # Boredom threshold\n",
    "        self.boredom_threshold = 4\n",
    "        \n",
    "    def action(self, _outcome):\n",
    "        \"\"\"Tracing the previous cycle\"\"\"\n",
    "        if self._action is not None:\n",
    "            # Check if prediction was correct\n",
    "            satisfied = (self._predicted_outcome == _outcome)\n",
    "            \n",
    "            # Update correct prediction counter\n",
    "            if satisfied:\n",
    "                self.correct_count += 1\n",
    "            else:\n",
    "                self.correct_count = 0\n",
    "            \n",
    "            # Check for boredom\n",
    "            bored = (self.correct_count >= self.boredom_threshold)\n",
    "            \n",
    "            print(f\"Action: {self._action}, Prediction: {self._predicted_outcome}, \"\n",
    "                  f\"Outcome: {_outcome}, Satisfaction: {satisfied}, Bored: {bored}\")\n",
    "            \n",
    "            # Update memory with the observed outcome\n",
    "            self.memory[self._action] = _outcome\n",
    "        \n",
    "        \"\"\"Computing the next action to enact\"\"\"\n",
    "        # TODO: Implement the agent's decision mechanism\n",
    "        # ✅ IMPLÉMENTATION DU MÉCANISME DE DÉCISION\n",
    "        if self.correct_count >= self.boredom_threshold:\n",
    "            # Switch action to avoid boredom\n",
    "            self._action = 1 - self._action  # Toggle between 0 and 1\n",
    "            self.correct_count = 0  # Reset boredom counter\n",
    "        elif self._action is None:\n",
    "            self._action = 0\n",
    "        \n",
    "        # TODO: Implement the agent's anticipation mechanism\n",
    "        # ✅ IMPLÉMENTATION DU MÉCANISME D'ANTICIPATION\n",
    "        if self._action in self.memory:\n",
    "            self._predicted_outcome = self.memory[self._action]\n",
    "        else:\n",
    "            self._predicted_outcome = 0\n",
    "        \n",
    "        return self._action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b3f5c-f48c-45ad-bf1d-4a703bac64af",
   "metadata": {},
   "source": [
    "## Test your agent in Environment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8025780-7d39-442d-9600-b40641e6d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 1, Satisfaction: False, Bored: False\n",
      "Action: 1, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: True\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: True\n",
      "Action: 1, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: True\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n"
     ]
    }
   ],
   "source": [
    "a = Agent1()\n",
    "e = Environment1()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02f401-3a78-4ced-9b8c-3b602c7be482",
   "metadata": {},
   "source": [
    "## Test your agent in Environment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "925fb5f1-1eb6-4dee-a59b-fd6384e123d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 0, Prediction: 0, Outcome: 1, Satisfaction: False, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: True\n",
      "Action: 0, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: True\n",
      "Action: 1, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: False\n",
      "Action: 1, Prediction: 0, Outcome: 0, Satisfaction: True, Bored: True\n",
      "Action: 0, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n",
      "Action: 0, Prediction: 1, Outcome: 1, Satisfaction: True, Bored: False\n"
     ]
    }
   ],
   "source": [
    "a = Agent1()\n",
    "e = Environment2()\n",
    "outcome = 0\n",
    "for i in range(20):\n",
    "    action = a.action(outcome)\n",
    "    outcome = e.outcome(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15a134-34a6-4039-9b43-f8fd76d93b5e",
   "metadata": {},
   "source": [
    "## Report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e661c15-c1ed-4512-a1d9-0fbdb8f91879",
   "metadata": {},
   "source": [
    "Explain what you programmed and what results you observed. Export this document as PDF including your code, the traces you obtained, and your explanations below (no more than a few paragraphs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc0899-eee2-404a-baf6-47741067e7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
